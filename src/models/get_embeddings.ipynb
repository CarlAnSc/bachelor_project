{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torchvision.models.resnet as resnet\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from lazypredict.Supervised import LazyClassifier\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.005077046405985571\n"
     ]
    }
   ],
   "source": [
    "val_preds  = pickle.load(open('../../val_preds.pkl', 'rb'))\n",
    "\n",
    "val_img_preds = []\n",
    "val_img_truth = []\n",
    "\n",
    "for i in val_preds.keys():\n",
    "   val_img_preds.append(torch.argmax(torch.from_numpy(val_preds[i][0]), dim=1))\n",
    "   val_img_truth.append(torch.from_numpy(val_preds[i][2]))\n",
    "\n",
    "all_truths = torch.cat(val_img_truth).numpy()\n",
    "all_preds = torch.cat(val_img_preds).numpy()\n",
    "\n",
    "#accuracy\n",
    "print('Accuracy: ', sklearn.metrics.accuracy_score(all_truths, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/annotations/imagenet_x_train_multi_factor.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UseMetaData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m annotation_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../../data/annotations/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/mnt/f/MetalabelIntegration/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m train_data \u001b[39m=\u001b[39m UseMetaData(\n\u001b[1;32m      8\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, path, annotation_path, transform\u001b[39m=\u001b[39mValTransforms()\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m val_data \u001b[39m=\u001b[39m UseMetaData(\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, path, annotation_path, transform\u001b[39m=\u001b[39mValTransforms())\n\u001b[1;32m     12\u001b[0m number_of_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_data\u001b[39m.\u001b[39mclasses)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UseMetaData' is not defined"
     ]
    }
   ],
   "source": [
    "dotenvpath = find_dotenv()\n",
    "load_dotenv(dotenvpath)\n",
    "\n",
    "annotation_path = '../../data/annotations/'\n",
    "path = '/mnt/f/MetalabelIntegration/'\n",
    "\n",
    "train_data = UseMetaData(\n",
    "        \"train\", path, annotation_path, transform=ValTransforms()\n",
    "    )\n",
    "val_data = UseMetaData(\"val\", path, annotation_path, transform=ValTransforms())\n",
    "    \n",
    "number_of_classes = len(train_data.classes)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=8,\n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=8,\n",
    "        num_workers=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.3473, -1.3987, -1.3987,  ..., -1.2103, -1.2274, -1.2274],\n",
       "          [-1.2959, -1.3130, -1.3130,  ..., -1.2103, -1.1760, -1.1589],\n",
       "          [-1.2788, -1.2788, -1.2445,  ..., -1.2103, -1.1760, -1.1418],\n",
       "          ...,\n",
       "          [-2.0665, -2.1008, -2.0837,  ..., -1.8953, -1.9124, -1.8953],\n",
       "          [-2.0837, -2.0837, -2.1008,  ..., -1.8610, -1.8610, -1.8439],\n",
       "          [-2.1008, -2.1008, -2.1008,  ..., -1.8610, -1.8439, -1.8610]],\n",
       " \n",
       "         [[ 1.0805,  1.0805,  1.0980,  ..., -0.6001, -0.6001, -0.6001],\n",
       "          [ 1.1155,  1.1506,  1.1506,  ..., -0.6176, -0.6001, -0.5826],\n",
       "          [ 1.1331,  1.1506,  1.1155,  ..., -0.6176, -0.6001, -0.5476],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -2.0182,  ..., -1.9132, -1.8782, -1.9307],\n",
       "          [-2.0357, -2.0182, -2.0357,  ..., -1.9657, -1.9307, -1.9482],\n",
       "          [-2.0357, -2.0182, -2.0357,  ..., -2.0182, -2.0182, -2.0182]],\n",
       " \n",
       "         [[ 1.4025,  1.3677,  1.3677,  ...,  0.1302,  0.1302,  0.1476],\n",
       "          [ 1.4025,  1.4200,  1.4200,  ...,  0.1302,  0.1476,  0.1476],\n",
       "          [ 1.4200,  1.4200,  1.4200,  ...,  0.1302,  0.1302,  0.1825],\n",
       "          ...,\n",
       "          [-1.5081, -1.5256, -1.5430,  ..., -1.2816, -1.2816, -1.3164],\n",
       "          [-1.5081, -1.5081, -1.5430,  ..., -1.3339, -1.2990, -1.3164],\n",
       "          [-1.5256, -1.5081, -1.5256,  ..., -1.3861, -1.3687, -1.3861]]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(len(val_loader.dataset.class_to_idx))\n",
    "print(len(train_loader.dataset.class_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.0777,  2.0777,  2.0948,  ...,  2.1462,  2.1804,  2.1633],\n",
       "          [ 2.1119,  2.0948,  2.0948,  ...,  2.1290,  2.1633,  2.1462],\n",
       "          [ 2.1290,  2.0948,  2.1119,  ...,  2.1462,  2.1290,  2.1804],\n",
       "          ...,\n",
       "          [-0.3369, -0.2684, -0.1828,  ...,  0.9646,  0.9817,  1.0159],\n",
       "          [-0.5938, -0.4397, -0.2513,  ...,  0.9646,  0.9817,  0.9132],\n",
       "          [-1.8439, -1.5357, -1.1932,  ...,  1.4269,  1.5297,  1.0331]],\n",
       " \n",
       "         [[ 2.3936,  2.3936,  2.4111,  ...,  2.0434,  2.0959,  2.0959],\n",
       "          [ 2.3936,  2.3936,  2.3936,  ...,  2.0434,  2.0784,  2.0784],\n",
       "          [ 2.3936,  2.3936,  2.3761,  ...,  1.9909,  2.0259,  2.0084],\n",
       "          ...,\n",
       "          [-0.0224, -0.0224,  0.0301,  ...,  0.8004,  0.8004,  0.8179],\n",
       "          [-0.2150, -0.0224,  0.0826,  ...,  0.8529,  0.7829,  0.8179],\n",
       "          [-1.6331, -1.3004, -0.8978,  ...,  1.2206,  1.1155,  0.8529]],\n",
       " \n",
       "         [[ 2.2740,  2.1868,  2.2566,  ...,  1.7860,  1.8383,  1.8557],\n",
       "          [ 2.2914,  2.3263,  2.3263,  ...,  1.7337,  1.8208,  1.8383],\n",
       "          [ 2.2043,  2.2914,  2.4134,  ...,  1.6814,  1.7685,  1.7685],\n",
       "          ...,\n",
       "          [ 0.3568,  0.4091,  0.5311,  ...,  0.8099,  0.7576,  0.7751],\n",
       "          [ 0.3045,  0.4439,  0.6531,  ...,  0.7576,  0.7402,  0.7751],\n",
       "          [-0.9853, -0.5670, -0.0964,  ...,  0.8971,  1.0017,  0.8274]]]),\n",
       " tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 572,\n",
       " '/mnt/f/MetalabelIntegration/val/n03443371/n03443371_18813.JPEG')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(val_dict[0][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kan ikke huske er embeddings lavet med et forward pass på de 50.000 billeder?**\n",
    "**Måske stadig spørge Nicki om hans approach med at lave embeddings på 50.000 images, for derefter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = pickle.load(open('../../data/train_embeddings.pkl', 'rb')) # De 50.000 billeder\n",
    "#val_dict = pickle.load(open('../../data/val_embeddings.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3433844 , 0.17441927, 1.7837598 , ..., 0.07956456, 0.11728598,\n",
       "        0.83721125],\n",
       "       [0.7219721 , 1.2102747 , 0.7870118 , ..., 0.3597971 , 0.14651966,\n",
       "        0.45646465],\n",
       "       [0.05431684, 0.09599383, 0.3473871 , ..., 0.24399187, 0.37392047,\n",
       "        0.08033226],\n",
       "       ...,\n",
       "       [0.12876727, 0.32736042, 0.0716015 , ..., 0.18868539, 0.6687686 ,\n",
       "        0.2971885 ],\n",
       "       [0.0243606 , 0.2680786 , 0.10872113, ..., 0.03809149, 0.        ,\n",
       "        0.3502503 ],\n",
       "       [0.20314777, 0.14395699, 0.13556641, ..., 0.1184201 , 0.51048464,\n",
       "        0.47193465]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_data = []\n",
    "# train_meta_data = []\n",
    "# train_labels = []\n",
    "\n",
    "val_img_data = []\n",
    "val_meta_data = []\n",
    "val_labels = []\n",
    "\n",
    "# for i in train_dict.keys():\n",
    "#     train_img_data.append(torch.from_numpy(train_dict[i][0]))\n",
    "#     train_meta_data.append(torch.from_numpy(train_dict[i][1]))\n",
    "#     train_labels.append(torch.from_numpy(train_dict[i][2]))\n",
    "\n",
    "for i in val_dict.keys():\n",
    "    val_img_data.append(torch.from_numpy(val_dict[i][0]))\n",
    "    val_meta_data.append(torch.from_numpy(val_dict[i][1]))\n",
    "    val_labels.append(torch.from_numpy(val_dict[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_data = torch.cat(train_img_data, 0).detach()\n",
    "# train_meta_data = torch.cat(train_meta_data, 0)\n",
    "# train_cat_data = torch.cat([train_img_data, train_meta_data], 1).numpy()\n",
    "# train_labels = torch.cat(train_labels, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_data = torch.cat(val_img_data, 0).detach()\n",
    "val_meta_data = torch.cat(val_meta_data, 0)\n",
    "val_cat_data = torch.cat([val_img_data, val_meta_data], 1).numpy()\n",
    "val_labels = torch.cat(val_labels, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cat_data = np.concatenate([train_cat_data, val_cat_data], 0)\n",
    "# all_labels = np.concatenate([train_labels, val_labels], 0)\n",
    "# all_img_data = np.concatenate([train_img_data, val_img_data], 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using k=?-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(classifier):\n",
    "\n",
    "    clf_cat = classifier()\n",
    "    clf_img = classifier()\n",
    "\n",
    "    clf_cat.fit(X_train_cat, y_train_cat)\n",
    "\n",
    "    y_pred_cat = clf_cat.predict(X_test_cat)\n",
    "\n",
    "    accuracy_cat = sklearn.metrics.accuracy_score(y_test_cat, y_pred_cat)\n",
    "\n",
    "    print('Accuracy cat: ', sklearn.metrics.accuracy_score(y_test_cat, y_pred_cat))\n",
    "\n",
    "    return clf_cat, clf_img, y_pred_cat, accuracy_cat\n",
    "\n",
    "def test_classifier_fold(classifier, X_train_cat, y_train_cat, X_test_cat, y_test_cat, X_train_img, y_train_img, X_test_img, y_test_img):\n",
    "\n",
    "    clf_cat = classifier()\n",
    "    clf_img = classifier()\n",
    "\n",
    "    clf_cat.fit(X_train_cat, y_train_cat)\n",
    "    clf_img.fit(X_train_img, y_train_img)\n",
    "\n",
    "\n",
    "    y_pred_cat = clf_cat.predict(X_test_cat)\n",
    "    y_pred_img = clf_img.predict(X_test_img)\n",
    "\n",
    "    accuracy_cat = sklearn.metrics.accuracy_score(y_test_cat, y_pred_cat)\n",
    "    accuracy_img = sklearn.metrics.accuracy_score(y_test_img, y_pred_img)\n",
    "\n",
    "    print('Accuracy cat: ', sklearn.metrics.accuracy_score(y_test_cat, y_pred_cat))\n",
    "    print('Accuracy img: ', sklearn.metrics.accuracy_score(y_test_img, y_pred_img))\n",
    "\n",
    "    return clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "Fold 1:\n",
      "Accuracy cat:  0.6521383261714754\n",
      "Accuracy img:  0.6513198281154082\n",
      "[[6341   33]\n",
      " [  25 3375]]\n",
      "Fold 2:\n",
      "Accuracy cat:  0.6601186822181297\n",
      "Accuracy img:  0.6582770615919787\n",
      "[[6415   37]\n",
      " [  19 3303]]\n",
      "Fold 3:\n",
      "Accuracy cat:  0.6657458563535912\n",
      "Accuracy img:  0.6651319828115408\n",
      "[[6480   27]\n",
      " [  21 3246]]\n",
      "Fold 4:\n",
      "Accuracy cat:  0.6619257137010129\n",
      "Accuracy img:  0.6617210682492581\n",
      "[[6438   31]\n",
      " [  29 3275]]\n",
      "Fold 5:\n",
      "Accuracy cat:  0.665097718203213\n",
      "Accuracy img:  0.6642791363961936\n",
      "[[6473   27]\n",
      " [  19 3254]]\n",
      "[[32147.   155.]\n",
      " [  113. 16453.]]\n",
      "   Using Meta  Just images     Delta  McNemar p-value\n",
      "0    0.652138     0.651320  0.000818         0.358020\n",
      "1    0.660119     0.658277  0.001842         0.019208\n",
      "2    0.665746     0.665132  0.000614         0.014868\n",
      "3    0.661926     0.661721  0.000205         0.026773\n",
      "4    0.665098     0.664279  0.000819         0.012263\n",
      "------------Cummulated McNemar test------------\n",
      "(6.272388059701493, 0.012263375366217383)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "\n",
    "\n",
    "X = val_cat_data\n",
    "\n",
    "N_splits = 5\n",
    "kf = KFold(n_splits=N_splits)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "df_acc = pd.DataFrame(columns=['Using Meta', 'Just images', 'Delta', 'McNemar p-value'])\n",
    "M_table_cumm = np.zeros((2,2))\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i + 1}:\")\n",
    "    _,_, y_pred_cat, y_pred_img, acc_cat, acc_img = test_classifier_fold(classifier=KNeighborsClassifier,\n",
    "                                                      X_train_cat = val_cat_data[train_index],\n",
    "                                                        y_train_cat = val_labels[train_index],\n",
    "                                                          X_test_cat = val_cat_data[test_index],\n",
    "                                                            y_test_cat = val_labels[test_index], \n",
    "                                                              X_train_img = val_img_data[train_index],\n",
    "                                                                y_train_img = val_labels[train_index],\n",
    "                                                                  X_test_img = val_img_data[test_index],\n",
    "                                                                    y_test_img = val_labels[test_index])\n",
    "    # Run a mcnemar test for the two classifiers\n",
    "    M_table = mcnemar_table(y_target= val_labels[test_index],\n",
    "                             y_model1 = y_pred_cat,\n",
    "                              y_model2 = y_pred_img)\n",
    "    print(M_table)\n",
    "    M_table_cumm += M_table\n",
    "    chi2, p = mcnemar(ary=M_table_cumm, corrected=True)\n",
    "    # append accuracies to df_acc\n",
    "    df_acc.loc[i] = [acc_cat, acc_img, acc_cat- acc_img, p]\n",
    "print(M_table_cumm)\n",
    "print(df_acc)\n",
    "print('------------Cummulated McNemar test------------')\n",
    "print(mcnemar(ary=M_table_cumm, corrected=True))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using k=1-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(val_cat_data, val_labels, test_size=0.2, random_state=42)\n",
    "X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(val_img_data, val_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# https://stackoverflow.com/questions/49134338/kfolds-cross-validation-vs-train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy cat:  0.6633926744423982\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img \u001b[39m=\u001b[39m test_classifier(KNeighborsClassifier)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img = test_classifier(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy cat:  0.7200736648250461\n",
      "Accuracy img:  0.7160834868017188\n"
     ]
    }
   ],
   "source": [
    "clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img = test_classifier(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img = test_classifier(xgb.XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier 1 - cat\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img = test_classifier(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_cat, clf_img, y_pred_cat, y_pred_img, accuracy_cat, accuracy_img = test_classifier(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006145898280929901\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(train_img_data, train_labels)\n",
    "preds = classifier.predict(val_img_data)\n",
    "print((preds == val_labels).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(val_cat_data[:1000], val_labels[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([524, 804, 826, ..., 524, 175, 495])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(val_cat_data[1000:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998772202668413\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(val_cat_data)\n",
    "print((preds == val_labels).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994474912007858\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(val_img_data, val_labels)\n",
    "preds = clf.predict(val_img_data)\n",
    "print((preds == val_labels).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      4\u001b[0m classifier \u001b[39m=\u001b[39m RandomForestClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train_img, y_train_img)\n\u001b[1;32m      6\u001b[0m preds \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test_img)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m((preds \u001b[39m==\u001b[39m y_test_img)\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(X_train_img, y_train_img)\n",
    "preds = classifier.predict(X_test_img)\n",
    "print((preds == y_test_img).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for train_data in tqdm([train_img_data, train_cat_data]):\n",
    "    classifier = DecisionTreeClassifier(random_state=0)\n",
    "    classifier.fit(train_data.numpy(), train_labels.numpy())\n",
    "    preds = classifier.predict(train_data.numpy())\n",
    "    acc = (preds == train_labels.numpy()).mean()\n",
    "    print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [08:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m classifier \u001b[39m=\u001b[39m GaussianNB()\n\u001b[1;32m      4\u001b[0m classifier\u001b[39m.\u001b[39mfit(train_data\u001b[39m.\u001b[39mnumpy(), train_labels\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m----> 5\u001b[0m preds \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mpredict(train_data\u001b[39m.\u001b[39;49mnumpy())\n\u001b[1;32m      6\u001b[0m acc \u001b[39m=\u001b[39m (preds \u001b[39m==\u001b[39m train_labels\u001b[39m.\u001b[39mnumpy())\u001b[39m.\u001b[39mmean()\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(acc)\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/naive_bayes.py:106\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    105\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[0;32m--> 106\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_joint_log_likelihood(X)\n\u001b[1;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/sklearn/naive_bayes.py:514\u001b[0m, in \u001b[0;36mGaussianNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    512\u001b[0m     jointi \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_prior_[i])\n\u001b[1;32m    513\u001b[0m     n_ij \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(\u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_[i, :]))\n\u001b[0;32m--> 514\u001b[0m     n_ij \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49msum(((X \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtheta_[i, :]) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39m/\u001b[39;49m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_[i, :]), \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    515\u001b[0m     joint_log_likelihood\u001b[39m.\u001b[39mappend(jointi \u001b[39m+\u001b[39m n_ij)\n\u001b[1;32m    517\u001b[0m joint_log_likelihood \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(joint_log_likelihood)\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/bach/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2183\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2113\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2114\u001b[0m \u001b[39m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2178\u001b[0m \n\u001b[1;32m   2179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m'\u001b[39m, a_min, a_max, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 2183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum_dispatcher\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2184\u001b[0m                     initial\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, where\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2185\u001b[0m     \u001b[39mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2188\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2190\u001b[0m         initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "for train_data in tqdm([train_img_data, train_cat_data]):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(train_data.numpy(), train_labels.numpy())\n",
    "    preds = classifier.predict(train_data.numpy())\n",
    "    acc = (preds == train_labels.numpy()).mean()\n",
    "    print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X = val_cat_data   #train_cat_data\n",
    "pca = PCA(n_components=1000)\n",
    "pca.fit(X)\n",
    "\n",
    "sns.scatterplot(np.cumsum(pca.explained_variance_ratio_*100))\n",
    "nr = np.where(np.cumsum(pca.explained_variance_ratio_*100) > 80)[0][0]\n",
    "\n",
    "plt.axhline(y=80, color='r', linestyle='-', label=f'80% explained variance with {nr} components')\n",
    "plt.legend()\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio vs Principal Component')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.790424"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_*100)[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "listo = []\n",
    "for X in [val_img_data, val_cat_data]:\n",
    "    pca = PCA(n_components=150)\n",
    "    pca.fit(X)\n",
    "    # do the PCA\n",
    "    X_pca = pca.transform(X)\n",
    "    listo.append(X_pca)\n",
    "\n",
    "dict_150_pca = {}\n",
    "\n",
    "dict_150_pca['img'] = listo[0]\n",
    "dict_150_pca['cat'] = listo[1]\n",
    "dict_150_pca['labels'] = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pca.shape\n",
    "# save the PCA data in pickle file\n",
    "with open('../../data/embeddings_PCA.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_150_pca, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "listo = []\n",
    "for X in [val_img_data, val_cat_data]:\n",
    "    pca = PCA(n_components=50)\n",
    "    pca.fit(X)\n",
    "    # do the PCA\n",
    "    X_pca = pca.transform(X)\n",
    "    listo.append(X_pca)\n",
    "\n",
    "dict_50_pca = {}\n",
    "\n",
    "dict_50_pca['img'] = listo[0]\n",
    "dict_50_pca['cat'] = listo[1]\n",
    "dict_50_pca['labels'] = val_labels\n",
    "\n",
    "# save the PCA data in pickle file\n",
    "with open('../../data/embeddings_PCA-ULTRA.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_50_pca, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting metalabel tabular data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenvpath = find_dotenv()\n",
    "load_dotenv(dotenvpath)\n",
    "\n",
    "annotation_path = \"../../data/annotations/\"\n",
    "path = '/mnt/f/MetalabelIntegration/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = UseMetaData(\n",
    "        \"train\", path, annotation_path, transform=ValTransforms()\n",
    "    )\n",
    "val_data = UseMetaData(\"val\", path, annotation_path, transform=ValTransforms())\n",
    "    \n",
    "number_of_classes = len(train_data.classes)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=16,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=16,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/juliu/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load(\n",
    "                \"pytorch/vision:v0.9.0\",\n",
    "                \"resnet50\",\n",
    "                weights=\"ResNet50_Weights.IMAGENET1K_V1\",\n",
    "            )\n",
    "model.fc = torch.nn.Identity()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_data = []\n",
    "train_meta_data = []\n",
    "train_labels = []\n",
    "\n",
    "for i, batch in enumerate(tqdm.tqdm(train_loader)):\n",
    "    train_img_data.append(model(batch[0]))\n",
    "    train_meta_data.append(batch[1])\n",
    "    train_labels.append(batch[2])\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "train_img_data = torch.cat(train_img_data, 0).detach()\n",
    "train_meta_data = torch.cat(train_meta_data, 0)\n",
    "train_cat_data = torch.cat([train_img_data, train_meta_data], 1)\n",
    "train_labels = torch.cat(train_labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Using Meta</th>\n",
       "      <th>Just images</th>\n",
       "      <th>Delta</th>\n",
       "      <th>McNemar p-value</th>\n",
       "      <th>Final p_1</th>\n",
       "      <th>Final theta_2</th>\n",
       "      <th>Final CI_2</th>\n",
       "      <th>Final p_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663290</td>\n",
       "      <td>0.662165</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.145120</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>(0.0009806031607664245, 0.002334448885514817)</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.662370</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>(0.0009806031607664245, 0.002334448885514817)</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.669224</td>\n",
       "      <td>0.667894</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.090559</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>(0.0009806031607664245, 0.002334448885514817)</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655684</td>\n",
       "      <td>0.654968</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.307228</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>(0.0009806031607664245, 0.002334448885514817)</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.660084</td>\n",
       "      <td>0.658037</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>(0.0009806031607664245, 0.002334448885514817)</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Using Meta  Just images     Delta  McNemar p-value  Final p_1  \\\n",
       "1    0.663290     0.662165  0.001125         0.145120   0.000002   \n",
       "2    0.662370     0.659300  0.003069         0.000275   0.000002   \n",
       "3    0.669224     0.667894  0.001330         0.090559   0.000002   \n",
       "4    0.655684     0.654968  0.000716         0.307228   0.000002   \n",
       "5    0.660084     0.658037  0.002046         0.006496   0.000002   \n",
       "\n",
       "   Final theta_2                                     Final CI_2  Final p_2  \n",
       "1       0.001658  (0.0009806031607664245, 0.002334448885514817)   0.000002  \n",
       "2       0.001658  (0.0009806031607664245, 0.002334448885514817)   0.000002  \n",
       "3       0.001658  (0.0009806031607664245, 0.002334448885514817)   0.000002  \n",
       "4       0.001658  (0.0009806031607664245, 0.002334448885514817)   0.000002  \n",
       "5       0.001658  (0.0009806031607664245, 0.002334448885514817)   0.000002  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../k-fold/k-nearest_mcnemar.csv', index_col=0)\n",
    "df.index = df.index + 1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Using Meta &  Just images &     Delta \\\\\n",
      "\\midrule\n",
      "1 &    0.663290 &     0.662165 &  0.001125 \\\\\n",
      "2 &    0.662370 &     0.659300 &  0.003069 \\\\\n",
      "3 &    0.669224 &     0.667894 &  0.001330 \\\\\n",
      "4 &    0.655684 &     0.654968 &  0.000716 \\\\\n",
      "5 &    0.660084 &     0.658037 &  0.002046 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0l/26n95fy50m782tbz32d5_1g40000gn/T/ipykernel_78504/1544154714.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.iloc[:,:3].to_latex())\n"
     ]
    }
   ],
   "source": [
    "# format latex table nicely\n",
    "print(df.iloc[:,:3].to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format latex table nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['Using Meta'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df['Just images'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0016575150954286633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00067691,  0.00067693])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.0009806031607664245, 0.002334448885514817]) -0.0016575150954286633\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6604729487460295"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621304638414581"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  6\n",
       "1  2  5\n",
       "2  3  4\n",
       "3  4  3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip([1,2,3,4],[6,5,4,3]), columns=['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2048, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "from torch import nn\n",
    "m = nn.AvgPool2d((1,1))\n",
    "# Without Learnable Parameters\n",
    "#m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(1, 1, 2048, 3)\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(input == output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=5).fit_transform(val_cat_data)\n",
    "X_embedded_img = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=5).fit_transform(val_img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Accuracy cat:  0.6340290566809904\n",
      "Accuracy img:  0.6326989973398813\n",
      "Fold 2:\n",
      "Accuracy cat:  0.625537139349294\n",
      "Accuracy img:  0.6250255780642521\n",
      "Fold 3:\n",
      "Accuracy cat:  0.6407816656435441\n",
      "Accuracy img:  0.6414978514426029\n",
      "Fold 4:\n",
      "Accuracy cat:  0.6316381868412975\n",
      "Accuracy img:  0.6284661823390976\n",
      "Fold 5:\n",
      "Accuracy cat:  0.6297963777755039\n",
      "Accuracy img:  0.6284661823390976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "classifier = KNeighborsClassifier\n",
    "N_splits = 5\n",
    "kf = KFold(n_splits=N_splits, shuffle=True, random_state=42)\n",
    "kf.get_n_splits(X_embedded)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_embedded)):\n",
    "        print(f\"Fold {i + 1}:\")\n",
    "        _,_, y_pred_cat, y_pred_img, acc_cat, acc_img = test_classifier_fold(classifier=classifier,\n",
    "                                                        X_train_cat = X_embedded[train_index],\n",
    "                                                            y_train_cat = val_labels[train_index],\n",
    "                                                            X_test_cat = X_embedded[test_index],\n",
    "                                                                y_test_cat = val_labels[test_index], \n",
    "                                                                X_train_img = X_embedded_img[train_index],\n",
    "                                                                    y_train_img = val_labels[train_index],\n",
    "                                                                    X_test_img = X_embedded_img[test_index],\n",
    "                                                                        y_test_img = val_labels[test_index])\n",
    "\n",
    "#classifier.fit(X_embedded[:9000], val_labels[:9000])\n",
    "\n",
    "#y_pred_cat = classifier.predict(X_embedded[9000:])\n",
    "\n",
    "#accuracy_cat = sklearn.metrics.accuracy_score(val_labels[9000:10000], y_pred_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.548"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 10000 elements, which is inconsistent with 'x' and 'y' with size 48868.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4375\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4374\u001b[0m \u001b[39mtry\u001b[39;00m:  \u001b[39m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[0;32m-> 4375\u001b[0m     colors \u001b[39m=\u001b[39m mcolors\u001b[39m.\u001b[39;49mto_rgba_array(c)\n\u001b[1;32m   4376\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/colors.py:487\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/colors.py:487\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/colors.py:299\u001b[0m, in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[1;32m    300\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/colors.py:381\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39miterable(c):\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(c) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 503.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(x\u001b[39m=\u001b[39;49mX_embedded[:,\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mX_embedded[:,\u001b[39m1\u001b[39;49m], c\u001b[39m=\u001b[39;49mval_labels[:\u001b[39m10000\u001b[39;49m], cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtab10\u001b[39;49m\u001b[39m'\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/pyplot.py:2790\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[1;32m   2786\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m   2787\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2788\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2789\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2790\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mscatter(\n\u001b[1;32m   2791\u001b[0m         x, y, s\u001b[39m=\u001b[39;49ms, c\u001b[39m=\u001b[39;49mc, marker\u001b[39m=\u001b[39;49mmarker, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   2792\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin, vmax\u001b[39m=\u001b[39;49mvmax, alpha\u001b[39m=\u001b[39;49malpha, linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[1;32m   2793\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors, plotnonfinite\u001b[39m=\u001b[39;49mplotnonfinite,\n\u001b[1;32m   2794\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2795\u001b[0m     sci(__ret)\n\u001b[1;32m   2796\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4538\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4535\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4536\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   4537\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[0;32m-> 4538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[1;32m   4539\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[1;32m   4540\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[1;32m   4542\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4543\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[0;32m~/anaconda3/envs/colo-repo/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4381\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_shape:\n\u001b[0;32m-> 4381\u001b[0m         \u001b[39mraise\u001b[39;00m invalid_shape_exception(c\u001b[39m.\u001b[39msize, xsize) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   4382\u001b[0m     \u001b[39m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[1;32m   4383\u001b[0m     \u001b[39m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[1;32m   4384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4385\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument must be a color, a sequence of colors, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4386\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mor a sequence of numbers, not \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 10000 elements, which is inconsistent with 'x' and 'y' with size 48868."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=X_embedded[:,0], y=X_embedded[:,1], c=val_labels[:10000], cmap='tab10', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colo-repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bcaae77deccda659b7240224c77c41f475b2ace73746821b6a2f4d3d41cec83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
